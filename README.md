# Multimodal Depression Detection

This project uses multimodal machine learning to detect signs of depression from user inputs including facial expressions, voice, video behavior, text input, and questionnaire responses.

## üß† Modalities
- **Image Analysis** (Facial expressions)
- **Audio Analysis** (Speech tone)
- **Video Analysis** (Facial + voice combined)
- **Text Analysis** (Free-text response)
- **Questionnaire** (MCQ and open-ended)

## ‚öôÔ∏è Tech Stack
- **Frontend**: React.js
- **Backend**: Python (Flask)
- **ML Models**: Pre-trained models adapted for depression detection
- **API**: DeepSeek, OpenAI (optional), custom-trained models

## üõ† How to Run

### Backend
```bash
cd backend
pip install -r requirements.txt
python app.py


Frontend

cd frontend
npm install
npm start